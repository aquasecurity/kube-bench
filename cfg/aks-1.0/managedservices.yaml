---
controls:
version: "aks-1.0"
id: 6
text: "Managed Services"
type: "managedservices"
groups:
  - id: 6.1
    text: "Image Registry and Image Scanning"
    checks:
      - id: 6.1.1
        text: "Ensure Image Vulnerability Scanning"
        type: "manual"
        remediation: |
          Scan your container images for vulnerabilities, and only deploy images that have passed validation. Regularly update the base images and application runtime, then redeploy workloads in the AKS cluster. Deployment workflow should include a process to scan container images using tools such as Twistlock or Aqua, and then only allow verified images to be deployed.
        scored: true

      - id: 6.1.2
        text: "Minimize user access to GCR (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To change roles at the GCR bucket level:
            Firstly, run the following if read permissions are required:

              gsutil iam ch [TYPE]:[EMAIL-ADDRESS]:objectViewer
              gs://artifacts.[PROJECT_ID].appspot.com

            Then remove the excessively privileged role (Storage Admin / Storage Object Admin /
            Storage Object Creator) using:

              gsutil iam ch -d [TYPE]:[EMAIL-ADDRESS]:[ROLE]
              gs://artifacts.[PROJECT_ID].appspot.com

            where:
              [TYPE] can be one of the following:
                    o user, if the [EMAIL-ADDRESS] is a Google account
                    o serviceAccount, if [EMAIL-ADDRESS] specifies a Service account
              [EMAIL-ADDRESS] can be one of the following:
                    o a Google account (for example, someone@example.com)
                    o a Cloud IAM service account
                    To modify roles defined at the project level and subsequently inherited within the GCR
                    bucket, or the Service Account User role, extract the IAM policy file, modify it accordingly
            and apply it using:

              gcloud projects set-iam-policy [PROJECT_ID] [POLICY_FILE]
        scored: true

      - id: 6.1.3
        text: "Minimize cluster access to read-only for GCR (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            For an account explicitly granted to the bucket. First, add read access to the Kubernetes
            Service Account

              gsutil iam ch [TYPE]:[EMAIL-ADDRESS]:objectViewer
              gs://artifacts.[PROJECT_ID].appspot.com

              where:
              [TYPE] can be one of the following:
                      o user, if the [EMAIL-ADDRESS] is a Google account
                      o serviceAccount, if [EMAIL-ADDRESS] specifies a Service account
              [EMAIL-ADDRESS] can be one of the following:
                      o a Google account (for example, someone@example.com)
                      o a Cloud IAM service account

              Then remove the excessively privileged role (Storage Admin / Storage Object Admin /
              Storage Object Creator) using:

                gsutil iam ch -d [TYPE]:[EMAIL-ADDRESS]:[ROLE]
                gs://artifacts.[PROJECT_ID].appspot.com

              For an account that inherits access to the GCR Bucket through Project level permissions,
              modify the Projects IAM policy file accordingly, then upload it using:

                gcloud projects set-iam-policy [PROJECT_ID] [POLICY_FILE]
        scored: true

      - id: 6.1.4
        text: "Minimize Container Registries to only those approved (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            First, update the cluster to enable Binary Authorization:

              gcloud container cluster update [CLUSTER_NAME] \
                --enable-binauthz

            Create a Binary Authorization Policy using the Binary Authorization Policy Reference
            (https://cloud.google.com/binary-authorization/docs/policy-yaml-reference) for guidance.
            Import the policy file into Binary Authorization:

              gcloud container binauthz policy import [YAML_POLICY]
        scored: false

  - id: 6.2
    text: "Identity and Access Management (IAM)"
    checks:
      - id: 6.2.1
        text: "Ensure GKE clusters are not running using the Compute Engine
        default service account (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Firstly, create a minimally privileged service account:

              gcloud iam service-accounts create [SA_NAME] \
                --display-name "GKE Node Service Account"
              export NODE_SA_EMAIL=`gcloud iam service-accounts list \
                --format='value(email)' \
                --filter='displayName:GKE Node Service Account'`

            Grant the following roles to the service account:

              export PROJECT_ID=`gcloud config get-value project`
              gcloud projects add-iam-policy-binding $PROJECT_ID \
                --member serviceAccount:$NODE_SA_EMAIL \
                --role roles/monitoring.metricWriter
              gcloud projects add-iam-policy-binding $PROJECT_ID \
                --member serviceAccount:$NODE_SA_EMAIL \
                --role roles/monitoring.viewer
              gcloud projects add-iam-policy-binding $PROJECT_ID \
                --member serviceAccount:$NODE_SA_EMAIL \
                --role roles/logging.logWriter

            To create a new Node pool using the Service account, run the following command:

              gcloud container node-pools create [NODE_POOL] \
                --service-account=[SA_NAME]@[PROJECT_ID].iam.gserviceaccount.com \
                --cluster=[CLUSTER_NAME] --zone [COMPUTE_ZONE]

            You will need to migrate your workloads to the new Node pool, and delete Node pools that
            use the default service account to complete the remediation.
        scored: true

      - id: 6.2.2
        text: "Prefer using dedicated GCP Service Accounts and Workload Identity (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:

              gcloud beta container clusters update [CLUSTER_NAME] --zone [CLUSTER_ZONE] \
                --identity-namespace=[PROJECT_ID].svc.id.goog

            Note that existing Node pools are unaffected. New Node pools default to --workload-
            metadata-from-node=GKE_METADATA_SERVER .

            Then, modify existing Node pools to enable GKE_METADATA_SERVER:

              gcloud beta container node-pools update [NODEPOOL_NAME] \
                --cluster=[CLUSTER_NAME] --zone [CLUSTER_ZONE] \
                --workload-metadata-from-node=GKE_METADATA_SERVER

            You may also need to modify workloads in order for them to use Workload Identity as
            described within https://cloud.google.com/kubernetes-engine/docs/how-to/workload-
            identity. Also consider the effects on the availability of your hosted workloads as Node
            pools are updated, it may be more appropriate to create new Node Pools.
        scored: false

  - id: 6.3
    text: "Cloud Key Management Service (Cloud KMS)"
    checks:
      - id: 6.3.1
        text: "Ensure Kubernetes Secrets are stored and retrieved from Azure Key Vault."
        type: "manual"
        remediation: |
          Use the Azure Key Vault with Secrets Store CSI Driver to retrieve secrets from Azure Key Vault and load it in the pod. See https://github.com/Azure/secrets-store-csi-driver-provider-azure.
        scored: true

  - id: 6.4
    text: "Node Metadata"
    checks:
      - id: 6.4.1
        text: "Ensure legacy Compute Engine instance metadata APIs are Disabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To update an existing cluster, create a new Node pool with the legacy GCE metadata
            endpoint disabled:

              gcloud container node-pools create [POOL_NAME] \
                --metadata disable-legacy-endpoints=true \
                --cluster [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE]

            You will need to migrate workloads from any existing non-conforming Node pools, to the
            new Node pool, then delete non-conforming Node pools to complete the remediation.
        scored: true

      - id: 6.4.2
        text: "Ensure the GKE Metadata Server is Enabled (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
              gcloud beta container clusters update [CLUSTER_NAME] \
                --identity-namespace=[PROJECT_ID].svc.id.goog
            Note that existing Node pools are unaffected. New Node pools default to --workload-
            metadata-from-node=GKE_METADATA_SERVER .

            To modify an existing Node pool to enable GKE Metadata Server:

              gcloud beta container node-pools update [NODEPOOL_NAME] \
                --cluster=[CLUSTER_NAME] \
                --workload-metadata-from-node=GKE_METADATA_SERVER

            You may also need to modify workloads in order for them to use Workload Identity as
            described within https://cloud.google.com/kubernetes-engine/docs/how-to/workload-
            identity.
        scored: false

  - id: 6.5
    text: "Node Configuration and Maintenance"
    checks:
      - id: 6.5.1
        text: "Ensure Container-Optimized OS (COS) is used for GKE node images (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To set the node image to cos for an existing cluster's Node pool:

              gcloud container clusters upgrade [CLUSTER_NAME]\
                --image-type cos \
                --zone [COMPUTE_ZONE] --node-pool [POOL_NAME]
        scored: true

      - id: 6.5.2
        text: "Ensure Node Auto-Repair is enabled for GKE nodes (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To enable node auto-repair for an existing cluster with Node pool, run the following
            command:

              gcloud container node-pools update [POOL_NAME] \
                --cluster [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --enable-autorepair
        scored: true

      - id: 6.5.3
        text: "Ensure Node Auto-Upgrade is enabled for GKE nodes (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To enable node auto-upgrade for an existing cluster's Node pool, run the following
            command:

              gcloud container node-pools update [NODE_POOL] \
                --cluster [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --enable-autoupgrade
        scored: true

      - id: 6.5.4
        text: "Automate GKE version management using Release Channels (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Create a new cluster by running the following command:

              gcloud beta container clusters create [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE] \
                --release-channel [RELEASE_CHANNEL]

            where [RELEASE_CHANNEL] is stable or regular according to your needs.
        scored: false

      - id: 6.5.5
        text: "Ensure Shielded GKE Nodes are Enabled (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To create a Node pool within the cluster with Integrity Monitoring enabled, run the
            following command:

              gcloud beta container node-pools create [NODEPOOL_NAME] \
                --cluster [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --shielded-integrity-monitoring

            You will also need to migrate workloads from existing non-conforming Node pools to the
            newly created Node pool, then delete the non-conforming pools.
        scored: false

      - id: 6.5.6
        text: "Ensure Shielded GKE Nodes are Enabled (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To migrate an existing cluster, you will need to specify the --enable-shielded-nodes flag
            on a cluster update command:

              gcloud beta container clusters update [CLUSTER_NAME] \
                --zone [CLUSTER_ZONE] \
                --enable-shielded-nodes
        scored: false

      - id: 6.5.7
        text: "Ensure Secure Boot for Shielded GKE Nodes is Enabled (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To create a Node pool within the cluster with Secure Boot enabled, run the following
            command:

              gcloud beta container node-pools create [NODEPOOL_NAME] \
                --cluster [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --shielded-secure-boot

            You will also need to migrate workloads from existing non-conforming Node pools to the
            newly created Node pool, then delete the non-conforming pools.
        scored: false

  - id: 6.6
    text: "Cluster Networking"
    checks:
      - id: 6.6.1
        text: "Enable VPC Flow Logs and Intranode Visibility (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To enable intranode visibility on an existing cluster, run the following command:

              gcloud beta container clusters update [CLUSTER_NAME] \
                --enable-intra-node-visibility
        scored: false

      - id: 6.6.2
        text: "Ensure use of VPC-native clusters (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To enable Alias IP on a new cluster, run the following command:

              gcloud container clusters create [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE] \
                --enable-ip-alias
        scored: true

      - id: 6.6.3
        text: "Ensure Master Authorized Networks is Enabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To check Master Authorized Networks status for an existing cluster, run the following
            command;

              gcloud container clusters describe [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE] \
                --format json | jq '.masterAuthorizedNetworksConfig'

            The output should return

              {
                "enabled": true
              }

            if Master Authorized Networks is enabled.

            If Master Authorized Networks is disabled, the
            above command will return null ( { } ).
        scored: true

      - id: 6.6.4
        text: "Ensure clusters are created with Private Endpoint Enabled and Public Access Disabled (Scored)"
        type: "manual"
        remediation: |
          In a private cluster, the control plane or API server has internal IP address.
        scored: true

      - id: 6.6.5
        text: "Ensure clusters are created with Private Nodes (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To create a cluster with Private Nodes enabled, include the --enable-private-nodes flag
            within the cluster create command:

              gcloud container clusters create [CLUSTER_NAME] \
                --enable-private-nodes

            Setting this flag also requires the setting of --enable-ip-alias and --master-ipv4-
            cidr=[MASTER_CIDR_RANGE] .
        scored: true

      - id: 6.6.6
        text: "Consider firewalling GKE worker nodes (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Use the following command to generate firewall rules, setting the variables as appropriate.
            You may want to use the target [TAG] and [SERVICE_ACCOUNT] previously identified.

              gcloud compute firewall-rules create FIREWALL_RULE_NAME \
                --network [NETWORK] \
                --priority [PRIORITY] \
                --direction [DIRECTION] \
                --action [ACTION] \
                --target-tags [TAG] \
                --target-service-accounts [SERVICE_ACCOUNT] \
                --source-ranges [SOURCE_CIDR-RANGE] \
                --source-tags [SOURCE_TAGS] \
                --source-service-accounts=[SOURCE_SERVICE_ACCOUNT] \
                --destination-ranges [DESTINATION_CIDR_RANGE] \
                --rules [RULES]
        scored: false

      - id: 6.6.7
        text: "Ensure Network Policy is Enabled and set as appropriate (Not Scored)"
        type: "manual"
        remediation: |
          Enable Azure Network Policy or Calico Network policy on the AKS cluster. See https://docs.microsoft.com/en-us/azure/aks/use-network-policies.
        scored: false

      - id: 6.6.8
        text: "Ensure use of Google-managed SSL Certificates (Not Scored)"
        type: "manual"
        remediation: |
          If services of type:LoadBalancer are discovered, consider replacing the Service with an
          Ingress.

          To configure the Ingress and use Google-managed SSL certificates, follow the instructions
          as listed at https://cloud.google.com/kubernetes-engine/docs/how-to/managed-certs.
        scored: false

  - id: 6.7
    text: "Logging"
    checks:
      - id: 6.7.1
        text: "Ensure Stackdriver Kubernetes Logging and Monitoring is Enabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:

            STACKDRIVER KUBERNETES ENGINE MONITORING SUPPORT (PREFERRED):
            To enable Stackdriver Kubernetes Engine Monitoring for an existing cluster, run the
            following command:

              gcloud container clusters update [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE] \
                --enable-stackdriver-kubernetes

            LEGACY STACKDRIVER SUPPORT:
            Both Logging and Monitoring support must be enabled.
            To enable Legacy Stackdriver Logging for an existing cluster, run the following command:

              gcloud container clusters update [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --logging-service logging.googleapis.com

            To enable Legacy Stackdriver Monitoring for an existing cluster, run the following
            command:

              gcloud container clusters update [CLUSTER_NAME] --zone [COMPUTE_ZONE] \
                --monitoring-service monitoring.googleapis.com
        scored: true

      - id: 6.7.2
        text: "Enable Azure Monitor for container for kubelet logs"
        type: "manual"
        remediation: |
          Enable Azure Monitor for containers via AKS diagnostics settings for collecting node and kubelet logs. See https://docs.microsoft.com/en-us/azure/azure-monitor/insights/container-insights-overview
        scored: false

  - id: 6.8
    text: "Authentication and Authorization"
    checks:
      - id: 6.8.1
        text: "Ensure Basic Authentication using static passwords is Disabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To update an existing cluster and disable Basic Authentication by removing the static
            password:

              gcloud container clusters update [CLUSTER_NAME] \
                --no-enable-basic-auth
        scored: true

      - id: 6.8.2
        text: "Ensure authentication using Client Certificates is Disabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Create a new cluster without a Client Certificate:

              gcloud container clusters create [CLUSTER_NAME] \
                --no-issue-client-certificate
        scored: true

      - id: 6.8.3
        text: "Use Azure RBAC for Kubernetes Authorization"
        type: "manual"
        remediation: |
          Enabling Azure RBAC for Kubernetes Authorization will use a Kubernetes Authorization webhook server to enable you to manage permissions and assignments of Azure AD-integrated K8s cluster resources using Azure role definition and role assignments. See https://docs.microsoft.com/en-us/azure/aks/manage-azure-rbac
        scored: false

      - id: 6.8.3
        text: "Use Kubernetes RBAC with Azure AD integration"
        type: "manual"
        remediation: |
          Don't use fixed credentials within pods or container images, as they are at risk of exposure or abuse. Instead, use pod identities to automatically request access to other Azure resources using a central Azure AD identity solution.  See https://docs.microsoft.com/en-us/azure/aks/operator-best-practices-identity#use-pod-identities
        scored: false

      - id: 6.8.3
        text: "Use pod identities"
        type: "manual"
        remediation: |
          Control access to cluster resources using role-based access control and Azure Active Directory identities in Azure Kubernetes Service. See https://docs.microsoft.com/en-us/azure/aks/azure-ad-rbac
        scored: false

      - id: 6.8.4
        text: "Ensure Legacy Authorization (ABAC) is Disabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To disable Legacy Authorization for an existing cluster, run the following command:

              gcloud container clusters update [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE] \
                --no-enable-legacy-authorization
        scored: true

  - id: 6.9
    text: "Storage"
    checks:
      - id: 6.9.1
        text: "Enable host-based encryption"
        type: "manual"
        remediation: |
          Enable host-based encryption on Azure Kubernetes Service (AKS). With host-based encryption, the data stored on the VM host of your AKS agent nodes' VMs is encrypted at rest and flows encrypted to the Storage service. This means the temp disks are encrypted at rest with platform-managed keys. The cache of OS and data disks is encrypted at rest with either platform-managed keys or customer-managed keys depending on the encryption type set on those disks. See https://docs.microsoft.com/en-us/azure/aks/enable-host-encryption.
        scored: false

      - id: 6.9.2
        text: "Bring your own keys (BYOK) with Azure disks in Azure Kubernetes Service (AKS)"
        type: "manual"
        remediation: |
          Azure Storage encrypts all data in a storage account at rest. By default, data is encrypted with Microsoft-managed keys. For additional control over encryption keys, you can supply customer-managed keys to use for encryption at rest for both the OS and data disks for your AKS clusters. See https://docs.microsoft.com/en-us/azure/aks/azure-disk-customer-managed-keys.
        scored: false

  - id: 6.10
    text: "Other Cluster Configurations"
    checks:
      - id: 6.10.1
        text: "Ensure Kubernetes Web UI is Disabled (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To disable the Kubernetes Dashboard on an existing cluster, run the following command:

              gcloud container clusters update [CLUSTER_NAME] \
                --zone [ZONE] \
                --update-addons=KubernetesDashboard=DISABLED
        scored: true

      - id: 6.10.2
        text: "Ensure that Alpha clusters are not used for production workloads (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Upon creating a new cluster

              gcloud container clusters create [CLUSTER_NAME] \
                --zone [COMPUTE_ZONE]

            Do not use the --enable-kubernetes-alpha argument.
        scored: true

      - id: 6.10.3
        text: "Secure pods with Azure Policy as appropriate"
        type: "manual"
        remediation: |
          Enable Azure Policy Add-on for AKS to control what functions pods are granted. See https://docs.microsoft.com/en-us/azure/aks/use-pod-security-on-azure-policy.
        scored: false

      - id: 6.10.4
        text: "Consider GKE Sandbox for running untrusted workloads (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            To enable GKE Sandbox on an existing cluster, a new Node pool must be created.

              gcloud container node-pools create [NODE_POOL_NAME] \
                --zone=[COMPUTE-ZONE] \
                --cluster=[CLUSTER_NAME] \
                --image-type=cos_containerd \
                --sandbox type=gvisor
        scored: false

      - id: 6.10.5
        text: "Ensure use of Binary Authorization (Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Firstly, update the cluster to enable Binary Authorization:

              gcloud container cluster update [CLUSTER_NAME] \
                --zone [COMPUTE-ZONE] \
                --enable-binauthz

            Create a Binary Authorization Policy using the Binary Authorization Policy Reference
            (https://cloud.google.com/binary-authorization/docs/policy-yaml-reference) for
            guidance.

            Import the policy file into Binary Authorization:

              gcloud container binauthz policy import [YAML_POLICY]
        scored: true

      - id: 6.10.6
        text: "Enable Cloud Security Command Center (Cloud SCC) (Not Scored)"
        type: "manual"
        remediation: |
          Using Command Line:
            Follow the instructions at https://cloud.google.com/security-command-
            center/docs/quickstart-scc-setup.
        scored: false
